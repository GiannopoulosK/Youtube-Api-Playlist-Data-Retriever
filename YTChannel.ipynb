{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Parse hours in time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Parameters\n",
    "api_key = os.environ.get('YOUTUBE-API-KEY')\n",
    "api = build('youtube', 'v3', developerKey = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_videos(api, playlist_id, max_results=50):\n",
    "    \"\"\"\n",
    "    Get videos from a YouTube playlist.\n",
    "\n",
    "    Args:\n",
    "    - api: YouTube Data API service object.\n",
    "    - playlist_id: ID of the playlist from which to get videos.\n",
    "    - max_results: Maximum number of results to get per page.\n",
    "\n",
    "    Returns:\n",
    "    - A list of dictionaries, each representing a video in the playlist.\n",
    "    \"\"\"\n",
    "    playlist_videos = []\n",
    "\n",
    "    # Initial playlist request\n",
    "    pl_request = api.playlistItems().list(\n",
    "        part='snippet',\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=max_results\n",
    "    )\n",
    "\n",
    "    # Retrieve all pages of videos\n",
    "    while pl_request:\n",
    "        pl_snippet = pl_request.execute()  # Execute the request\n",
    "        playlist_videos.extend(pl_snippet['items'])  # Add videos to the list\n",
    "        pl_request = api.playlistItems().list_next(pl_request, pl_snippet)  # Check for more pages until all videos are pulled\n",
    "\n",
    "    return playlist_videos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_publish_dates(playlist_videos):\n",
    "    publish_dates = []\n",
    "    for video_info in playlist_videos:\n",
    "        if 'snippet' in video_info and video_info['snippet'].get('title') != 'Private video':\n",
    "            publish_dates.append(video_info['snippet'].get('publishedAt'))\n",
    "    return publish_dates\n",
    "\n",
    "def extract_video_ids(playlist_videos):\n",
    "    video_ids = []\n",
    "    for video_info in playlist_videos:\n",
    "        if 'snippet' in video_info and video_info['snippet'].get('title') != 'Private video':\n",
    "            video_ids.append(video_info['snippet'].get('resourceId', {}).get('videoId'))\n",
    "    return video_ids\n",
    "\n",
    "def extract_titles(playlist_videos):\n",
    "    titles = []\n",
    "    for video_info in playlist_videos:\n",
    "        if 'snippet' in video_info and video_info['snippet'].get('title') != 'Private video':\n",
    "            titles.append(video_info['snippet']['title'])\n",
    "    return titles\n",
    "\n",
    "def extract_descriptions(playlist_videos):\n",
    "    descriptions = []\n",
    "    for video_info in playlist_videos:\n",
    "        if 'snippet' in video_info and video_info['snippet'].get('title') != 'Private video':\n",
    "            descriptions.append(video_info['snippet'].get('description'))\n",
    "    return descriptions\n",
    "\n",
    "def extract_video_duration(video_content_details_responses):\n",
    "    \"\"\"Function to extract video durations from video content details response.\"\"\"\n",
    "    durations = []\n",
    "    for item in video_content_details_responses:\n",
    "        durations.append(item['contentDetails'].get('duration'))\n",
    "    return durations\n",
    "\n",
    "\n",
    "def extract_video_definition(video_content_details_responses):\n",
    "    \"\"\"Function to extract video definitions from video content details response.\"\"\"\n",
    "    definitions = []\n",
    "    for item in video_content_details_responses:\n",
    "        definitions.append(item['contentDetails'].get('definition'))\n",
    "    return definitions\n",
    "\n",
    "\n",
    "def extract_view_count(video_statistics_response):\n",
    "    \"\"\"Function to extract view counts from video statistics response.\"\"\"\n",
    "    view_counts = []\n",
    "    for item in video_statistics_response:\n",
    "        view_counts.append(item['statistics'].get('viewCount'))\n",
    "    return view_counts\n",
    "\n",
    "def extract_like_count(video_statistics_responses):\n",
    "    \"\"\"Function to extract like counts from video statistics response.\"\"\"\n",
    "    like_counts = []\n",
    "    for item in video_statistics_responses:\n",
    "        like_counts.append(item['statistics'].get('likeCount'))\n",
    "    return like_counts\n",
    "\n",
    "def extract_favorite_count(video_statistics_response):\n",
    "    \"\"\"Function to extract favorite counts from video statistics response.\"\"\"\n",
    "    favorite_counts = []\n",
    "    for item in video_statistics_response:\n",
    "        favorite_counts.append(item['statistics'].get('favoriteCount'))\n",
    "    return favorite_counts\n",
    "\n",
    "def extract_comment_count(video_statistics_response):\n",
    "    \"\"\"Function to extract comment counts from video statistics response.\"\"\"\n",
    "    comment_counts = []\n",
    "    for item in video_statistics_response:\n",
    "        comment_counts.append(item['statistics'].get('commentCount'))\n",
    "    return comment_counts\n",
    "\n",
    "def extract_topic_categories(video_topic_response):\n",
    "    \"\"\"Function to extract topic categories from video topic response.\"\"\"\n",
    "    topic_categories = []\n",
    "    for item in video_topic_response:\n",
    "        try:\n",
    "            topic_categories.append(item['topicDetails'].get('topicCategories'))\n",
    "        except Exception as e:\n",
    "            topic_categories.append(None)\n",
    "        \n",
    "    return topic_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(lst, batch_size):\n",
    "    \"\"\"Function to split a list into batches.\"\"\"\n",
    "    for i in range(0, len(lst), batch_size):\n",
    "        yield lst[i:i + batch_size]\n",
    "\n",
    "def get_video_statistics(video_ids):\n",
    "    \"\"\"Function to get statistics for a list of video IDs.\"\"\"\n",
    "    batch_size = 50  # Adjust batch size based on API limits\n",
    "    all_videos_stats = []\n",
    "\n",
    "    for batch in split_list(video_ids, batch_size):\n",
    "        video_ids_str = ','.join(batch)\n",
    "        stat_request = api.videos().list(part='statistics', id=video_ids_str)\n",
    "\n",
    "        try:\n",
    "            response = stat_request.execute()\n",
    "            all_videos_stats.extend(response['items'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting statistics for batch {batch}: {e}\")\n",
    "\n",
    "    return all_videos_stats\n",
    "\n",
    "def get_video_topic_details(video_ids):\n",
    "    \"\"\"Function to get topic details for a list of video IDs.\"\"\"\n",
    "    batch_size = 50  # Adjust batch size based on API limits\n",
    "    all_video_topic_details = []\n",
    "\n",
    "    for batch in split_list(video_ids, batch_size):\n",
    "        video_ids_str = ','.join(batch)\n",
    "        topic_request = api.videos().list(part='topicDetails', id=video_ids_str)\n",
    "\n",
    "        try:\n",
    "            response = topic_request.execute()\n",
    "            all_video_topic_details.extend(response['items'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting topic details for batch {batch}: {e}\")\n",
    "\n",
    "    return all_video_topic_details\n",
    "\n",
    "def get_video_content_details(video_ids):\n",
    "    \"\"\"Function to get content details for a list of video IDs.\"\"\"\n",
    "    batch_size = 50  # Adjust batch size based on API limits\n",
    "    all_video_content_details = []\n",
    "\n",
    "    for batch in split_list(video_ids, batch_size):\n",
    "        video_ids_str = ','.join(batch)\n",
    "        content_request = api.videos().list(part='contentDetails', id=video_ids_str)\n",
    "\n",
    "        try:\n",
    "            response = content_request.execute()\n",
    "            all_video_content_details.extend(response['items'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting content details for batch {batch}: {e}\")\n",
    "\n",
    "    return all_video_content_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_df(api, playlist_id):\n",
    "    # Get Playlist Videos\n",
    "    playlist_videos = get_playlist_videos(api, playlist_id)\n",
    "\n",
    "    # Get Video Info\n",
    "    publish_dates = extract_publish_dates(playlist_videos)\n",
    "    video_ids = extract_video_ids(playlist_videos)\n",
    "    titles = extract_titles(playlist_videos)\n",
    "    descriptions = extract_descriptions(playlist_videos)\n",
    "\n",
    "    # Get Video Content Details\n",
    "    content_details = get_video_content_details(video_ids)\n",
    "\n",
    "    video_durations = extract_video_duration(content_details)\n",
    "    video_hd = extract_video_definition(content_details)\n",
    "\n",
    "    # Get Video Stats\n",
    "    stats = get_video_statistics(video_ids)\n",
    "\n",
    "    video_views = extract_view_count(stats)\n",
    "    video_likes = extract_like_count(stats)\n",
    "    video_favorites = extract_favorite_count(stats)\n",
    "    video_comments = extract_comment_count(stats)\n",
    "\n",
    "    # Get Topic Details\n",
    "    topic_details = get_video_topic_details(video_ids)\n",
    "\n",
    "    topic_categories = extract_topic_categories(topic_details)\n",
    "    \n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'PublishDate': publish_dates,\n",
    "        'VideoId': video_ids,\n",
    "        'Title': titles,\n",
    "        'Description': descriptions,\n",
    "        'Duration': video_durations,\n",
    "        'HD': video_hd,\n",
    "        'Views': video_views,\n",
    "        'Likes': video_likes,\n",
    "        'Favorites': video_favorites,\n",
    "        'Comments': video_comments,\n",
    "        'TopicCategories': topic_categories\n",
    "    })\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(df):\n",
    "    df[['Date', 'Time']] = df['PublishDate'].str.split('T', expand=True)\n",
    "    df['Time'] = df['Time'].str.rstrip('Z')\n",
    "    df.drop(columns=['PublishDate'], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_duration(df):\n",
    "    def parse_duration(duration):\n",
    "        hours = 0\n",
    "        minutes = 0\n",
    "        seconds = 0\n",
    "\n",
    "        hours_match = re.search(r'(\\d+)H', duration)\n",
    "        minutes_match = re.search(r'(\\d+)M', duration)\n",
    "        seconds_match = re.search(r'(\\d+)S', duration)\n",
    "\n",
    "        if hours_match:\n",
    "            hours = int(hours_match.group(1))\n",
    "        if minutes_match:\n",
    "            minutes = int(minutes_match.group(1))\n",
    "        if seconds_match:\n",
    "            seconds = int(seconds_match.group(1))\n",
    "\n",
    "        total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "        return total_seconds\n",
    "\n",
    "    new_df = df.copy()\n",
    "    new_df['TotalSeconds'] = df['Duration'].apply(parse_duration)\n",
    "    new_df.drop(columns=['Duration'], inplace=True)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def parse_topic_categories(df):\n",
    "    df['TopicCategories'] = df['TopicCategories'].apply(lambda x: [url.replace('https://en.wikipedia.org/wiki/', '') if url is not None else None for url in x] if isinstance(x, list) else None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df_temp = df.copy()\n",
    "    df_temp = parse_date(df_temp)\n",
    "    df_temp = parse_duration(df_temp)\n",
    "    df_temp = parse_topic_categories(df_temp)\n",
    "    \n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_playlist_df(api, playlist_id='PLjkZIuJPz3rOwDyDazAKJIaniwTxwZ970')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>HD</th>\n",
       "      <th>Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Comments</th>\n",
       "      <th>TopicCategories</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TotalSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZR9R4I7dLw8</td>\n",
       "      <td>20 WOMEN VS 2 SIDEMEN: ANGRY GINGE &amp; DANNY AAR...</td>\n",
       "      <td>🎥: Watch the 20v2 BTS: https://watch.sideplus....</td>\n",
       "      <td>hd</td>\n",
       "      <td>16107996</td>\n",
       "      <td>504415</td>\n",
       "      <td>0</td>\n",
       "      <td>9697</td>\n",
       "      <td>[Entertainment]</td>\n",
       "      <td>2024-01-18</td>\n",
       "      <td>11:24:15</td>\n",
       "      <td>5063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m7YSTtiPMl4</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: SPEED EDITION</td>\n",
       "      <td>🎥: WATCH THE SPEED BTS here: https://watch.sid...</td>\n",
       "      <td>hd</td>\n",
       "      <td>55621360</td>\n",
       "      <td>2143633</td>\n",
       "      <td>0</td>\n",
       "      <td>46924</td>\n",
       "      <td>[Lifestyle_(sociology)]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:31:05</td>\n",
       "      <td>4529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NNePgYyI-Ns</td>\n",
       "      <td>SIDEMEN REVERSE 20 VS 1: TANA MONGEAU EDITION</td>\n",
       "      <td>🍗: Order food NOW at: https://www.eatsides.com...</td>\n",
       "      <td>hd</td>\n",
       "      <td>11853625</td>\n",
       "      <td>409853</td>\n",
       "      <td>0</td>\n",
       "      <td>11650</td>\n",
       "      <td>[Entertainment, Film, Television_program]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:30:58</td>\n",
       "      <td>3684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gzJND7rlajM</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: DEJI EDITION</td>\n",
       "      <td>Deji speaks to females\\n🎥: Catch ALL of the ac...</td>\n",
       "      <td>hd</td>\n",
       "      <td>14075149</td>\n",
       "      <td>565822</td>\n",
       "      <td>0</td>\n",
       "      <td>16640</td>\n",
       "      <td>[Entertainment]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:30:51</td>\n",
       "      <td>3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lz4R4FHFr90</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: KAI CENAT EDITION</td>\n",
       "      <td>🎥: WATCH THE KAI BTS here: https://watch.sidep...</td>\n",
       "      <td>hd</td>\n",
       "      <td>64072436</td>\n",
       "      <td>1812020</td>\n",
       "      <td>0</td>\n",
       "      <td>44069</td>\n",
       "      <td>[Entertainment, Humour, Television_program]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:30:39</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M0zEjvvTsoc</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: LOGAN PAUL EDITION</td>\n",
       "      <td>Today Logan Paul takes on Sidemen 20 vs 1. Enj...</td>\n",
       "      <td>hd</td>\n",
       "      <td>24678738</td>\n",
       "      <td>956098</td>\n",
       "      <td>0</td>\n",
       "      <td>22378</td>\n",
       "      <td>[Entertainment, Film]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:30:29</td>\n",
       "      <td>3259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WB4LhvhLzlw</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: JIDION EDITION</td>\n",
       "      <td>JiDion's Channel: https://www.youtube.com/c/Ji...</td>\n",
       "      <td>hd</td>\n",
       "      <td>19771971</td>\n",
       "      <td>850394</td>\n",
       "      <td>0</td>\n",
       "      <td>58728</td>\n",
       "      <td>[Entertainment, Television_program]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:30:20</td>\n",
       "      <td>3635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DUrBIxB1q0o</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: FILLY EDITION</td>\n",
       "      <td>Filly's Channel: https://www.youtube.com/c/Yun...</td>\n",
       "      <td>hd</td>\n",
       "      <td>41625671</td>\n",
       "      <td>1395657</td>\n",
       "      <td>0</td>\n",
       "      <td>33136</td>\n",
       "      <td>[Humour, Lifestyle_(sociology)]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:30:14</td>\n",
       "      <td>4366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qG3AS3RKlF0</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: CALLUX EDITION</td>\n",
       "      <td>Callux Channel: https://www.youtube.com/channe...</td>\n",
       "      <td>hd</td>\n",
       "      <td>15203055</td>\n",
       "      <td>667242</td>\n",
       "      <td>0</td>\n",
       "      <td>22440</td>\n",
       "      <td>[Lifestyle_(sociology)]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:29:58</td>\n",
       "      <td>3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hiehLFrTlRs</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: KSI EDITION</td>\n",
       "      <td>olajide olatunji dates some lovely ladies\\n🍗: ...</td>\n",
       "      <td>hd</td>\n",
       "      <td>26822630</td>\n",
       "      <td>941601</td>\n",
       "      <td>0</td>\n",
       "      <td>24223</td>\n",
       "      <td>[Lifestyle_(sociology)]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:29:48</td>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VYEtNWp5VgA</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: HARRY EDITION</td>\n",
       "      <td>👉🏻 Subscribe to our 2nd Channel: https://www.y...</td>\n",
       "      <td>hd</td>\n",
       "      <td>35543010</td>\n",
       "      <td>1421188</td>\n",
       "      <td>0</td>\n",
       "      <td>67036</td>\n",
       "      <td>[Entertainment, Film, Humour, Television_program]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:06:32</td>\n",
       "      <td>2963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oois7rlbO8g</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN: ETHAN EDITION</td>\n",
       "      <td>20 WOMEN VS 1 SIDEMEN \\n👉🏻 Subscribe to our 2n...</td>\n",
       "      <td>hd</td>\n",
       "      <td>20912871</td>\n",
       "      <td>944457</td>\n",
       "      <td>0</td>\n",
       "      <td>39917</td>\n",
       "      <td>[Lifestyle_(sociology)]</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>12:06:17</td>\n",
       "      <td>2370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VideoId                                              Title  \\\n",
       "0   ZR9R4I7dLw8  20 WOMEN VS 2 SIDEMEN: ANGRY GINGE & DANNY AAR...   \n",
       "1   m7YSTtiPMl4               20 WOMEN VS 1 SIDEMEN: SPEED EDITION   \n",
       "2   NNePgYyI-Ns      SIDEMEN REVERSE 20 VS 1: TANA MONGEAU EDITION   \n",
       "3   gzJND7rlajM                20 WOMEN VS 1 SIDEMEN: DEJI EDITION   \n",
       "4   lz4R4FHFr90           20 WOMEN VS 1 SIDEMEN: KAI CENAT EDITION   \n",
       "5   M0zEjvvTsoc          20 WOMEN VS 1 SIDEMEN: LOGAN PAUL EDITION   \n",
       "6   WB4LhvhLzlw              20 WOMEN VS 1 SIDEMEN: JIDION EDITION   \n",
       "7   DUrBIxB1q0o               20 WOMEN VS 1 SIDEMEN: FILLY EDITION   \n",
       "8   qG3AS3RKlF0              20 WOMEN VS 1 SIDEMEN: CALLUX EDITION   \n",
       "9   hiehLFrTlRs                 20 WOMEN VS 1 SIDEMEN: KSI EDITION   \n",
       "10  VYEtNWp5VgA               20 WOMEN VS 1 SIDEMEN: HARRY EDITION   \n",
       "11  oois7rlbO8g               20 WOMEN VS 1 SIDEMEN: ETHAN EDITION   \n",
       "\n",
       "                                          Description  HD     Views    Likes  \\\n",
       "0   🎥: Watch the 20v2 BTS: https://watch.sideplus....  hd  16107996   504415   \n",
       "1   🎥: WATCH THE SPEED BTS here: https://watch.sid...  hd  55621360  2143633   \n",
       "2   🍗: Order food NOW at: https://www.eatsides.com...  hd  11853625   409853   \n",
       "3   Deji speaks to females\\n🎥: Catch ALL of the ac...  hd  14075149   565822   \n",
       "4   🎥: WATCH THE KAI BTS here: https://watch.sidep...  hd  64072436  1812020   \n",
       "5   Today Logan Paul takes on Sidemen 20 vs 1. Enj...  hd  24678738   956098   \n",
       "6   JiDion's Channel: https://www.youtube.com/c/Ji...  hd  19771971   850394   \n",
       "7   Filly's Channel: https://www.youtube.com/c/Yun...  hd  41625671  1395657   \n",
       "8   Callux Channel: https://www.youtube.com/channe...  hd  15203055   667242   \n",
       "9   olajide olatunji dates some lovely ladies\\n🍗: ...  hd  26822630   941601   \n",
       "10  👉🏻 Subscribe to our 2nd Channel: https://www.y...  hd  35543010  1421188   \n",
       "11  20 WOMEN VS 1 SIDEMEN \\n👉🏻 Subscribe to our 2n...  hd  20912871   944457   \n",
       "\n",
       "   Favorites Comments                                    TopicCategories  \\\n",
       "0          0     9697                                    [Entertainment]   \n",
       "1          0    46924                            [Lifestyle_(sociology)]   \n",
       "2          0    11650          [Entertainment, Film, Television_program]   \n",
       "3          0    16640                                    [Entertainment]   \n",
       "4          0    44069        [Entertainment, Humour, Television_program]   \n",
       "5          0    22378                              [Entertainment, Film]   \n",
       "6          0    58728                [Entertainment, Television_program]   \n",
       "7          0    33136                    [Humour, Lifestyle_(sociology)]   \n",
       "8          0    22440                            [Lifestyle_(sociology)]   \n",
       "9          0    24223                            [Lifestyle_(sociology)]   \n",
       "10         0    67036  [Entertainment, Film, Humour, Television_program]   \n",
       "11         0    39917                            [Lifestyle_(sociology)]   \n",
       "\n",
       "          Date      Time  TotalSeconds  \n",
       "0   2024-01-18  11:24:15          5063  \n",
       "1   2024-01-08  12:31:05          4529  \n",
       "2   2024-01-08  12:30:58          3684  \n",
       "3   2024-01-08  12:30:51          3577  \n",
       "4   2024-01-08  12:30:39          3148  \n",
       "5   2024-01-08  12:30:29          3259  \n",
       "6   2024-01-08  12:30:20          3635  \n",
       "7   2024-01-08  12:30:14          4366  \n",
       "8   2024-01-08  12:29:58          3682  \n",
       "9   2024-01-08  12:29:48          3110  \n",
       "10  2024-01-08  12:06:32          2963  \n",
       "11  2024-01-08  12:06:17          2370  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
